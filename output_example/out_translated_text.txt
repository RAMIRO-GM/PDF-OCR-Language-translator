1406.266lv1 [stat ML] 10 de junio 2014

mi
mi

ar X1Vv

 

Redes generativas adversarias

Ian J. Goodfellow, Jean Pouget-Abadie; Mehdi Mirza, Bing Xu, David Warde-Farley,
Sherjil Ozair! Aaron Courville, Yoshua Bengio *
Departamento d’Informatique et de recherche opérationnelle

Universidad de Montreal
Montreal, QC H3C 3J7

Resumen

Se propone un nuevo marco para la estimación de los modelos generativos a través de un proceso contradictorio, en el que al mismo tiempo entrenamos dos modelos: un modelo generativo G
que captura la distribución de datos, y un modelo discriminativo D que las estimaciones
la probabilidad de que una muestra de vino de los datos de entrenamiento en lugar de G. El procedimiento de entrenamiento para G' es maximizar la probabilidad de cometer un error D. Esta
marco corresponde a un Minimax juego de dos jugadores. En el espacio de arbitraria
funciones G y D, existe una solución única, con G recuperación de los datos de entrenamiento
distribución y D igual a 5 en todas partes. En el caso donde se definen G y D
por perceptrones multicapa, todo el sistema puede ser entrenado con propagación hacia atrás.
No hay necesidad de ningún cadenas de Markov o redes de inferencia aproximados desenrollados durante entrenamiento o generación de muestras. Los experimentos demuestran
el potencial del marco mediante una evaluación cualitativa y cuantitativa de
las muestras generadas.

1. Introducción

La promesa de aprendizaje profundo es descubrir los modelos jerárquicos ricos, [2] que representan la probabilidad
distribuciones más de los tipos de datos se encuentran en aplicaciones de inteligencia artificial, como naturales
imágenes, formas de onda de audio que contiene voz y símbolos en los corpus de lenguaje natural. Hasta ahora, el
la mayoría de los éxitos notables en el aprendizaje profundo tienen modelos discriminativos involucradas, por lo general aquellas que
asignar una entrada sensorial de alta dimensión, rica a una etiqueta de clase [14, 22]. Estos éxitos sorprendentes tienen
principalmente ha basado en los algoritmos de retropropagación y deserción, utilizando lineal a trozos unidades
[19, 9, 10], que tiene un gradiente particular de buen comportamiento. modelos generativos profundos han tenido menos
de un impacto, debido a la dificultad de la aproximación de muchos cálculos probabilísticos que intratables
surgir en estimación de máxima verosimilitud y estrategias relacionadas, y debido a la dificultad de apalancamiento
los beneficios de trozos lineales de unidades en el contexto generativo. Proponemos un nuevo modelo generativo
procedimiento de estimación que deja de lado estas dificultades. !

En el marco redes contradictorio propuesto, el modelo generativo se enfrenta a un adversario: una
modelo discriminativo que aprende para determinar si una muestra es de la distribución de modelo o de la
distribución de datos. El modelo generativo puede ser pensado como algo análogo a un equipo de falsificadores,
tratando de producir moneda falsa y utilizarlo sin detección, mientras que el modelo es discriminativo
análoga a la policía, tratando de detectar la falsificación de moneda. La competencia en este juego drives
Ambos equipos para mejorar sus métodos hasta que las falsificaciones son indistiguishable de la genuina
artículos.

“Jean-Pouget Abadie está de visita en la Universidad de Montreal de la Escuela Politécnica.

'Sherjil Ozair está de visita en la Universidad de Montreal, del Instituto Indio de Tecnología de Delhi

* Yoshua Bengio es un CIFAR Senior Fellow.

'Todo el código y hiperparámetros disponible en http: //www.github.com/goodfeli/adversarialEste marco puede producir algoritmos específicos de formación para muchos tipos de modelo y optimización
algoritmo. En este artículo se analiza el caso especial cuando el modelo generativo genera muestras
haciendo pasar el ruido aleatorio a través de un perceptrón de múltiples capas, y el modelo discriminativo es también una
perceptrón multicapa. Nos referimos a este caso especial como redes de confrontación. En este caso, podemos entrenar
ambos modelos usando sólo el backpropagation gran éxito y algoritmos de deserción [17] y
muestra desde el modelo generativo utilizando sólo propagación hacia adelante. No inferencia aproximada o
Las cadenas de Markov son necesarios.

2. Trabajo relacionado

Una alternativa a modelos gráficos dirigidos con variables latentes están no dirigidos modelos gráficos
con variables latentes, tales como máquinas de Boltzmann restringidos (RBM) [27, 16], en el fondo Boltzmann
máquinas (DBMS) [26] y sus numerosas variantes. Las interacciones dentro de tales modelos son
representada como el producto de funciones potenciales no normalizadas, normalizado por una suma / integración global sobre todos los estados de las variables aleatorias. Esta cantidad (la función de partición) y
su gradiente son intratables para todos, pero la mayoría de los casos triviales, aunque pueden ser estimados
la cadena de Markov Monte Carlo (MCMC) métodos. Mezcla plantea un problema importante para el aprendizaje
Los algoritmos que se basan en MCMC (3, 5].

redes de creencias profundas (DBNs) [16] son ​​modelos híbridos que contienen una sola capa no dirigido y varias capas dirigidas. Si bien existe un criterio de formación por capas rápida aproximada, incurren en la DBNs
dificultades de cálculo asociados con ambos modelos no dirigida y dirigida.

criterios alternativos que no lo hacen aproximada o unido al también han sido propuestos de probabilidad logarítmica,
tales como puntuación de coincidencia [18] y la estimación de ruido-contrastivo (NCE) [13]. Ambos requieren la
densidad de probabilidad aprendido a ser especificado analíticamente hasta una constante de normalización. Tenga en cuenta que
en muchos modelos generativos interesantes con varias capas de variables latentes (como DBNs y
DBMS), ni siquiera es posible derivar una densidad de probabilidad no normalizada tratable. algunos modelos
como autoencoders eliminación de ruido [30] y autoencoders contractivas tienen reglas muy similares aprendizaje
de puntuación de adaptación aplicado a los mismos mecanismos. En NCE, como en este trabajo, un criterio de entrenamiento discriminativo es
empleado para ajustar un modelo generativo. Sin embargo, en lugar de ajustar un modelo discriminativo independiente, la
propio modelo generativo se usa para discriminar datos generados a partir de muestras de una distribución de ruido fijo.
Debido a NCE utiliza una distribución de ruido fijo, disminuye drásticamente después de aprender el modelo ha aprendido
incluso una distribución aproximadamente correcta sobre un pequeño subconjunto de las variables observadas.

Por último, algunas técnicas no implican la definición de una distribución de probabilidad de manera explícita, sino que entrenan
una máquina generativo para extraer muestras a partir de la distribución deseada. Este enfoque tiene la ventaja
que tales máquinas pueden ser diseñados para ser entrenado por retropropagación. el trabajo reciente más importante en este
área incluye la red estocástico generativa (GSN) marco [5], que se extiende generalizarse
eliminación de ruido auto-codificadores [4]: ​​ambas pueden ser vistas como la definición de una cadena de Markov parametrizado, es decir, uno
aprende los parámetros de una máquina que realiza un paso de una cadena de Markov generativo. Comparado
a GSN, el marco de las redes de confrontación no requiere una cadena de Markov para el muestreo. Porque
redes de confrontación no requieren circuitos de retroalimentación durante la generación, están en mejores condiciones de apalancamiento
unidades lineales por partes [19, 9, 10], que mejoran el rendimiento de backpropagation pero tienen
problemas con la activación sin límites cuando se utiliza ina bucle de realimentación. Más ejemplos recientes de la formación
una máquina generadora por propagan hacia atrás en ella incluyen trabajos recientes sobre variacional de auto-codificación
Bayes [20] y backpropagation estocástico [24].

3 redes Acusatorios

El marco de modelado de confrontación es más sencillo de aplicar cuando los modelos son a la vez
perceptrones multicapa. Para conocer la distribución P del generador, a través de datos X, definimos un sobre antes
de entrada variables de ruido p, (z), entonces representa una asignación a espacio de datos como G (z; 6,), donde G' es una
función diferenciable representado por un perceptrón multicapa con parámetros 6 ,. También definimos una
segundo perceptrón multicapa D (x; 6,) que da salida a un solo escalar. D (a) representa la probabilidad
x que vinieron de los datos en lugar de PG. Formamos a D para maximizar la probabilidad de que la asignación de la
correcta etiqueta para ambos ejemplos de entrenamiento y muestras de G. Nos entrenamos simultáneamente G para minimizar
log (1 - D (G (z))):En otras palabras, D y G juegan el siguiente juego minimax de dos jugadores con función de valor V (G, D):

min max V (D, G) = Eanpaa (x) (log D (@)] + Eznp, (z) [log (1 -. D (G (z)))] (1)

En la siguiente sección, se presenta un análisis teórico de las redes de confrontación, esencialmente mostrando que
el criterio de formación permite a uno para recuperar la distribución de generación de datos como se dan G y D
suficiente capacidad, 1.e, en el límite no paramétrico. Ver Figura | para un menos formal, más pedagógico
explicación del enfoque. En la práctica, debemos poner en práctica el juego usando un proceso iterativo, numérica
Acercarse. Optimización D hasta su finalización en el bucle interno de la formación es computacionalmente prohibitivo,
y en conjuntos de datos finitos daría lugar a un ajuste por exceso. En su lugar, se alternan entre k pasos de optimización
D y un paso de optimizar los resultados G. esto en D se mantienen cerca de su solución óptima, por lo
siempre y cuando G cambia lentamente suficiente. Esta estrategia es análoga a la forma en que SML / PCD [31, 29]
formación mantiene muestras de una cadena de Markov de un paso de aprendizaje a la siguiente con el fin de evitar
ardor en una cadena de Markov como parte del bucle interior de aprendizaje. El procedimiento se presenta formalmente
en el algoritmo 1.

En la práctica, la ecuación 1 puede no proporcionar gradiente suficiente para G para aprender bien. A principios de aprendizaje,
cuando G es pobre, D puede rechazar muestras con alta confianza, ya que son claramente diferentes de
los datos de entrenamiento. En este caso, log (1 - D ()) Z G () se satura. En lugar de la formación de G para minimizar
log (1 - D (G (z))) podemos entrenar G para maximizar log D (G (z)). Esta función objetivo se traduce en la
mismo punto fijo de la dinámica de G y D, pero ofrece mucho más fuertes gradientes temprano en el aprendizaje.

  

   

  

s
e e

‘s
- N / A .
’Ae.
.
.
y
e e
‘
y
mi
.
.
4 eee
@ ® fy ‘
+ @ 18, =
wae una
La SY

(a B C D)

Figura 1: Redes de confrontación generativos son entrenados por actualizar simultáneamente la distribución discriminativo
(D, azul, línea discontinua) de modo que discrimina entre las muestras de la distribución de generación de datos (negro,
línea de puntos) pz de los de la distribución pg generativa (G) (verde, línea sólida). La línea horizontal inferior es
el dominio desde el que z es muestreada, en este caso de manera uniforme. La línea horizontal arriba es parte del dominio
de un. Las flechas hacia arriba muestran cómo el mapeo a = G (z) aplica la distribución de p no uniforme, en
muestras transformadas. G contrae en regiones de alta densidad y se expande en las regiones de baja densidad de pg. (una)
Consideremos un par de adversarios cerca de la convergencia: PG es similar a los datos y D es un clasificador parcialmente exacta.
(B) En el bucle interno del algoritmo D está capacitado para muestras diferenciar de datos, convergiendo a D * (x) =
SNS (c) Después de una actualización de G, gradiente de D ha guiado G (z) fluya a las regiones que tienen más probabilidades
para ser clasificado como de datos. (D) Después de varias etapas de formación, si G y D tienen capacidad suficiente, van a llegar a una
punto en el que ambos no pueden mejorar porque pg = Paata. El discriminador es incapaz de diferenciar entre

las dos distribuciones, es decir. D (a) = $ 5.

4 resultados teóricos

El generador G' define implícitamente una distribución de probabilidad p, como la distribución de las muestras
G (z) obtiene cuando z ~ pz. Por lo tanto, nos gustaría Algoritmo 1 a converger a un buen estimador
De Paata, 1F dado suficiente capacidad y tiempo de entrenamiento. Los resultados de esta sección se realizan en un entorno no paramétrico, por ejemplo representamos un modelo con capacidad infinita mediante el estudio de la convergencia en el
espacio de las funciones de densidad de probabilidad.

Vamos a mostrar en la sección 4.1 que este juego Minimax tiene un óptimo global para PG = Pdata. Lo haremos
a continuación, mostrar en la sección 4.2 que el algoritmo | optimiza la ecuación 1, obteniendo así el resultado deseado.Algoritmo 1 Minibatch formación estocástico pendiente de descenso de las redes adversarias generativos. El número de
Pasos para aplicar al discriminador, k, es una hiperparámetro. Utilizamos k = 1, la opción menos costosa, en nuestra
experimentos.
para el número de iteraciones de entrenamiento hacer
para k pasos hacen

e minibatch de muestra de las muestras de ruido m {z, ..., 2 °} de p ruido antes, (z).
e minibatch de muestra de m ejemplos Fe), Ley ap) de distribución de generación de datos
Paata (2).

e Actualizar el discriminador ascendiendo su gradiente estocástico:

Voe ~>. [Log D (2) + 10 ¢ (1 - D (E (2)))).

wl

para terminar
e minibatch de muestra de las muestras de ruido m {z “), ..., 2} de py ruido antes (z).
e actualización del generador al descender de su gradiente estocástico:

Vor Yates (I ~ (@ (2))).

para terminar
Las actualizaciones basadas en gradiente pueden utilizar cualquier regla estándar aprendizaje basado en el gradiente. Utilizamos impulso en nuestros experimentos.

 

4.1 Global optimalidad de p, = Paata
Consideramos en primer lugar la óptima discriminador D para cualquier generador dada G.
Propuesta 1. Para G fijo, el óptimo discriminador D es

SE __ Paata (X)
Data) = Paata (®) + Pg (2) *)

Prueba. El criterio de formación para el discriminador D, teniendo en cuenta cualquier generador G, es maximizar el
cantidad V (G, D)

V (G, D) = / pAAA () log (D (a)) dx + / p2 (z) log (1 - D (g (z))) dz

WV z

= / PAAA (a @) log (D (a)) + pg (a) log (1 - D (a)) da (3)

Para cualquier (a, b) R €? \ {0,0}, la función y> álogo (y) + diario (1 - y) alcanza su máximo en
[0, 1] a <5. El discriminador no tiene que ser definida fuera de Sop (Pdata) U Sop (PQ),
la conclusión de la prueba. LJ

Tenga en cuenta que el objetivo de entrenamiento para D puede interpretarse como maximizar el diario de probabilidad para estimar la probabilidad condicional P (Y = y | a), donde Y indica si x viene de Paata
(Con y = 1) o desde pg (con y = 0). El juego Minimax en la ecuación. 1 ahora se puede reformular como:

C (G) = V max (G, D)
Bev puallog Di, (a)] + Exxp, [log (1 - DE (G (2))) (4)
= Ej ~ registro de ping DG (x)] + Ex ~ p, [log (1 - DG (x))]

Pdata (a) | Dg ()
= Exxpi, registro = e + - | + Eany, [log - ~ 2 4+ -_
° ° Paata (£) + Pg (x) ns ° Paata (X) + Dg (x)Teorema 1. El mínimo global del criterio de la formación virtual C (G) se logra si y sólo si
Pg = Paata. En ese punto, CG) alcanza el valor - log 4.

5? nosotros
encontrar C (G) = log 4 + log $ = - log 4. Para ver que este es el mejor valor posible de C (G), alcanzado
sólo para py = Paata, observar que

Prueba. Para pg = PDAA, D (x) = 5, (considerar. Eq 2). Por lo tanto, mediante la inspección de la ecuación. 4 en el DE, (x) = 4

Kew pana [- log 2] + EXNP, [-log 2] = - log 4
y que restando esta expresión de C '(G’)) = V (D &, G), se obtiene:

C (Q) = -log (4) + KL (como (5)

 

 

Pd a + p
Ss t) enn (n,

 

 

Pdata + P g
2

donde KL es la divergencia de Kullback-Leibler. Reconocemos en la expresión anterior el Jensen-
divergencia Shannon entre la distribución del modelo y el proceso de generación de datos:

C (@) = -log (4) 2 ISD (PASA || P) 6)

Desde la divergencia Jensen-Shannon entre dos distribuciones es siempre no negativa y cero
solamente cuando son iguales, hemos demostrado que C * = - log (4) es el mínimo global de C '(G) y
que la única solución es py = Pdata, 1. €., el modelo generativo perfectamente replicar la generación de datos de
proceso. L

4.2 Convergencia del algoritmo 1

Proposición 2. IfG y D tienen suficiente capacidad, y en cada paso del algoritmo I, el discriminador
se le permite alcanzar su óptima dada G, y PG se actualiza a fin de mejorar el criterio

Fenian registro de DE (x)] + Ex ~ p, [log (1 - DG (x))]

converge entonces pg a DDATA

Prueba. Considere V (G, D) = U (pg, D) como una función de pg como hecho en el criterio anterior. Nota
que U (p ,, D) es convexa en p ,. Los subderivatives de un extremo superior de funciones convexas incluyen la
derivada de la función en el punto donde se alcanza el máximo. En otras palabras, si f (a) =
supgca fa (x) y f (x) es convexa en x para cada una, a continuación, OFG (x) € De si 6 = argsupyey fa (Z).
Esto es equivalente a calcular una actualización de descenso de gradiente para p, en el óptimo D dada la correspondiente G .. supp U (p ,, D) es convexa en pg con una optima global única como probados en Thm 1,
por lo tanto, con suficientemente pequeñas actualizaciones de pg, p, converge a p ;, finales la prueba. |

 

En la práctica, las redes de confrontación representan una familia limitado de p, distribuciones a través de la función G (z; 6,),
y optimizamos 6, en lugar de en sí pg. El uso de un perceptrón multicapa para definir G introduce
múltiples puntos críticos en el espacio de parámetros. Sin embargo, el excelente desempeño de múltiples capas perceptrones en la práctica sugiere que son un modelo razonable para el uso a pesar de su falta de teórico
garantías.

5 experimentos

Hemos capacitado a las redes adversarias una una serie de conjuntos de datos incluyendo MNIST [23], la base de datos de Toronto de la cara
(TFD) [28], y CIFAR-10 [21]. Las redes de generador utilizado una mezcla de activaciones lineales rectificador [19,
9] y activaciones sigmoideas, mientras que el discriminador MAXOUT usado neto [10] activaciones. Dropout [17]
se aplicó en el entrenamiento de la red discriminador. Si bien nuestro marco teórico permite el uso de
deserción y otros ruidos en las capas intermedias de la generador, hemos utilizado el ruido como la entrada a solamente
la capa inferior de la red del generador.

Estimamos la probabilidad de los datos del conjunto de prueba bajo p, mediante la instalación de una ventana de Gauss a la Parzen
muestras generadas con G y que informan de la probabilidad log-bajo esta distribución. El parámetro omodelo | MNIST TFD
DBN [3] 138 2 1,909 + 66
Stacked CAE [3] | 121 + 1,6 | 2110 + 50
Profunda GSN [6] 214 + 1,1 | 1890 + 29
redes de confrontación 225 + 2 | 2057 + 26

 

Tabla 1: estimaciones de probabilidad logarítmica basados ​​en ventanas de Parzen. Los números reportados en MNIST son los loglikelihood media de las muestras en la prueba de conjunto, con el error estándar de la media calculada a través de ejemplos. En TFD, nos
calculado el error estándar a través de pliegues de la base de datos, con una o diferentes elegidos utilizando el conjunto de validación de
cada pliegue. En TFD, o era validación cruzada en cada diario de probabilidad veces y media en cada pliegue se calcularon.
Para MNIST comparamos con otros modelos de la versión (en lugar de binario)-valor real del conjunto de datos.

de las gaussianas se obtuvo mediante la validación cruzada en el conjunto de validación. Este procedimiento se introdujo en Breuleux et al. [8] y se utiliza para diversos modelos generativos para la que la probabilidad exacta
no es tratable [25, 3, 5]. Los resultados se presentan en la Tabla 1. Este método de estimación de la probabilidad
tiene un poco alta varianza y no funciona bien en espacios de alta dimensión, pero es la mejor
método disponible para nuestro conocimiento. Los avances en los modelos generativos que se muestra, pero no estimar
probabilidad motivar directamente la investigación adicional en la forma de evaluar este tipo de modelos.

En las figuras 2 y 3 se muestra muestras extraídas de la red del generador después del entrenamiento. A pesar de que no hacemos
afirmación de que estas muestras son mejores que las muestras generadas por los métodos existentes, creemos que estos
Las muestras son al menos competitivo con los mejores modelos generativos en la literatura y ponen de manifiesto la
potencial del marco de confrontación.

 

Figura 2: Visualización de las muestras procedentes del modelo. espectáculos de columna más a la derecha del ejemplo de formación más cercano de
la muestra vecina, con el fin de demostrar que el modelo no ha memorizado el conjunto de entrenamiento. Las muestras
están justo al azar dibuja, recogidos a cereza no. A diferencia de la mayoría de las otras visualizaciones de modelos generativos profundas, éstas
imágenes muestran muestras reales de las distribuciones de modelo, significa no condicionales que les dieron muestras de unidades ocultas.
Por otra parte, estas muestras no están correlacionados porque el proceso de muestreo no depende de la cadena de Markov
mezclar. a) MNIST b) TFD c) CIFAR-10 (modelo totalmente conectado) d) CIFAR-10 (discriminador convolucional
y el generador “deconvolucional”)SERPS PSPSPS PIEI ELE. PAVAPAPALAVALALALA EZ

Figura 3: Dígitos obtenidos por interpolación lineal entre las coordenadas en z espacio del modelo completo.

 

 

 

 

Profundo dirigida profundo no dirigidos generativo;
modelos de confrontación
modelos gráficos gráfica de modelos autoencoders
inerence n eeceH forzadas solución de compromiso.
durante el entrenamiento. entre mixin Sincronización de la
. Inferencia necesaria MCMC necesitaba e discriminador con
El entrenamiento de dur; a 'y poder de
urante la formación. aproximado . el generador.
ni: la reconstrucción:
función de partición’Helvetica.
; Generacion
degradado.
Aprendido variacional MCMC-basa aprendido
Inferencia aproximada; ; aproximado
. inferencia inferencia
inferencia inferencia
No hay dificultades de muestreo Requiere Requiere Markov Markov No hay dificultades
cadena de la cadena
No explícitamente no explícitamente
Intratable, puede ser | Intratable, puede ser | representado, pueden estar | representado, puede ser
La evaluación de p (x) | aproximada con aproximada con aproximada aproximada con la
densidad Parzen densidad AIS AIS Parzen
la estimación de la estimación
Casi todos los modelos de diseño cuidadoso Cualquier diferenciable Cualquier diferenciables
; ; función es función se
Modelo extrema diseño incurrir necesaria para asegurar h ‘h llamada‘llamada
dificultad múltiples propiedades neue) Miporenealy
permitida la permitida

Tabla 2: Retos en la modelización generativa: un resumen de las dificultades que encuentran los diferentes enfoques
al modelado generativo de profundidad para cada una de las principales operaciones que implican un modelo.

6 Ventajas y desventajas

Este nuevo marco viene con ventajas y desventajas relativas a marcos de modelos anteriores. Las desventajas son principalmente que no hay una representación explícita de p, (a), y que D
debe ser sincronizado bien con G durante el entrenamiento (en particular, G no debe ser entrenado demasiado
sin actualizar D, a fin de evitar “el escenario Helvetica” en la que G se derrumba demasiados valores
de z en el mismo valor de x para tener suficiente diversidad para modelo pgata), tanto como las cadenas negativas de una
máquina de Boltzmann debe mantenerse al día entre las etapas de aprendizaje. Las ventajas son que Markov
Nunca se necesitan cadenas, solamente Backprop se utiliza para obtener gradientes, no se necesita ninguna inferencia durante
aprendizaje, y una amplia variedad de funciones se pueden incorporar en el modelo. La Tabla 2 resume
la comparación de las redes de confrontación con otros generadores de modelado generativo se acerca.

Las ventajas antes mencionadas son principalmente computacional. modelos de confrontación también pueden ganar
alguna ventaja estadística de la red del generador no está actualizando directamente con ejemplos de datos, pero sólo con gradientes fluyen a través del discriminador. Esto significa que los componentes de la
de entrada no se copian directamente en los parámetros del generador. Otra de las ventajas de las redes contradictorio es que pueden representar muy fuerte, incluso distribuciones degeneradas, mientras que los métodos basados ​​en
cadenas de Markov requieren que la distribución sea algo borrosa a fin de que las cadenas para poder
mezclar entre los modos.

7 Conclusiones y trabajo futuro

Este marco admite muchas extensiones directas:

1. Un condicional modelo generativo p (a | c) se puede obtener mediante la adición de c como entrada a ambos G y D.

2. Learned inferencia aproximada se puede realizar mediante la formación de una red auxiliar de predecir z
x dados. Esto es similar a la red de inferencia entrenado por el algoritmo de sueño-vigilia [15] pero con
la ventaja de que la red de inferencia puede ser entrenado para un generador neto fijo después de que el generador
Net ha terminado el entrenamiento.3. Una aproximadamente puede modelar todos los condicionales p (ags | 2 g) en la que S es un subconjunto de los índices
de x mediante la formación de una familia de modelos condicionales que los parámetros de las acciones. En esencia, se puede utilizar
redes de confrontación para implementar una extensión estocástica del determinista MP-DBM [11].

4. El aprendizaje semi-supervisado: características del discriminador o inferencia neta podría mejorar el desempeño de los clasificadores cuando los datos de la etiqueta disponible es limitada.

5. Mejora de la eficiencia: la formación se podría acelerar en gran medida por los mejores métodos para divising
coordinación de G y D o determinar mejores distribuciones para z muestra de durante el entrenamiento.

En este trabajo se ha demostrado la viabilidad de la estructura del modelo de confrontación, lo que sugiere que
estas líneas de investigación podrían resultar útiles.

Expresiones de gratitud

Nos gustaría reconocer Patrice Marcotte, Olivier Delalleau, Kyunghyun Cho, Guillaume
Alain y Jason Yosinski útil para los debates. Yann Dauphin comparte su código de evaluación ventana Parzen con nosotros. Nos gustaría dar las gracias a los desarrolladores de Pylearn2 [12] y Teano [7, 1],
particularmente Frédéric Bastien quien corrió una característica Teano específicamente para beneficiar a este proyecto. Arnaud Bergeron proporciona un apoyo muy necesario con 4TRX archivos de texto. También nos gustaría dar las gracias
Cifar, y Canadá Investigación Sillas de financiación, y calcular Canadá y Québec para Calcul
la provisión de recursos computacionales. Ian Goodfellow es apoyada por la beca en 2013 Google
Aprendizaje profundo. Por último, nos gustaría dar las gracias a Les Trois Brasseurs para estimular nuestra creatividad.

referencias

[1] Bastien, F, Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I. J., Bergeron, A., Bouchard, N., y
Bengio, Y. (2012). Teano: nuevas características y mejoras de velocidad. Aprendizaje y profunda sin supervisión
Característica de aprendizaje NIPS 2012 Taller.

[2] Bengio, Y. (2009). El aprendizaje profundo arquitecturas para la IA. Ahora editores.

[3] Bengio, Y., Mesnil, G., Dauphin, Y., y Rifai, S. (2013a). Mejor mezcla a través de representaciones profundas. En
ICML’/ 3.

[4] Bengio, Y., Yao, L., Alain, G., y Vincent, P. (2013b). Generalizadas eliminación de ruido auto-generativa como codificadores
modelos. En NJPS26. Fundación pellizcos.

[5] Bengio, Y., Thibodeau-Laufer, E., y Yosinski, J. (2014A). Profunda generativa estocástico redes entrenable
por Backprop. En ICML’/ 4.

[6] Bengio, Y., Thibodeau-Laufer, E., Alain, G., y Yosinski, J. (2014b). redes estocásticos generativos profundas entrenable por Backprop. En Actas de la Conferencia Internacional 30ª en aprendizaje automático
(ICML’14).

[7] Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Warde-Farley,
D., y Bengio, Y. (2010). Teano: una CPU y GPU matemáticas expresión compilador. En Actas de la
Python para Scientific Computing Conference (SciPy). Presentación oral.

[8] Breuleux, O., Bengio, Y., y Vincent, P. (2011). generar rápidamente muestras representativas de una
proceso RBM-deriva. Neural Computation, 23 (8), 2053-2073.

[9] Glorot, X., Bordes, A., y Bengio, Y. (2011). redes neuronales rectificador de profundidad escasa. En AISTATS'201 1.

[10] Goodfellow, I. J., Warde-Farley, D., Mirza, M., Courville, A., y Bengio, Y. (2013a). MAXOUT redes.
En ICML'2013.

[11] Goodfellow, I. J., Mirza, M., Courville, A., y Bengio, Y. (2013b). Multi-predicción profunda Boltzmann
máquinas. En NJPS'2013.

[12] Goodfellow, I. J., Warde-Farley, D., Lamblin, P., Dumoulin, V., Mirza, M., Pascanu, R., Bergstra,
J., Bastien, F y Bengio, Y. (2013c). Pylearn2: una biblioteca de investigación de aprendizaje automático. arXiv
arXiv: 1308.4214.

[13] Gutmann, M. y Hyvarinen, A. (2010). estimación del ruido-contrastivo: Un nuevo principio para la estimación
modelos estadísticos no normalizadas. En AJSTATS'2010.

[14] Hinton, G., Deng, L., Dahl, G. E., Mohamed, A., Jaitly, N., Senior, A., Vanhoucke, V., Nguyen, P.,
Sainath, T., y Kingsbury, B. (2012a). redes neuronales profundas para el modelado acústico en el reconocimiento de voz.
Revista IEEE Procesamiento de Señales, 29 (6), 82-97.

[15] Hinton, G. E., Dayan, P., Frey, B. J., y Neal, R. M. (1995). El algoritmo de sueño-vigilia para no supervisado
Redes neuronales. Science, 268, 1558-1161.[16] Hinton, G. E., Osindero, S., y Teh, Y. (2006). Un algoritmo de aprendizaje rápido para redes de creencias profundas. Neural
Computation, 18, 1527-1554.

[17] Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., y Salakhutdinov, R. (2012b). Mejorando
redes neuronales mediante la prevención de co-adaptación de detectores de rasgos. Informe técnico, arXiv: 1207.0580.

[18] Hyvarinen, A. (2005). Estimación de modelos estadísticos no normalizados utilizando correspondencia de puntuación. J. máquina
Learning Res., 6.

[19] Jarrett, K., Kavukcuoglu, K., Ranzato, M., y LeCun, Y. (2009). ¿Cuál es la mejor arquitectura de múltiples etapas
para el reconocimiento de objetos? En Proc. Iccv (ICCV'09), páginas 2146-2153.
IEEE.

[20] Kingma, D. P. y Welling, M. (2014). Auto-codificación de Bayes variacional. En Actas de la Conferencia Internacional sobre Representaciones de Aprendizaje (ICLR).

[21] Krizhevsky, A. y Hinton, G. (2009). Aprender múltiples capas de características de pequeñas imágenes. Técnico
informe de la Universidad de Toronto.

[22] Krizhevsky, A., Sutskever, I., y Hinton, G. (2012). Clasificación IMAGEnet con profunda convolucional
Redes neuronales. En NJPS'2012.

[23] LeCun, Y., Bottou, L., Bengio, Y., y Haffner, P. (1998). aprendizaje basado en gradiente aplicado a documentos
reconocimiento. Actas de la IEEE, 86 (11), 2278-2324.

[24] Rezende, D. J., Mohamed, S., y Wierstra, D. (2014). backpropagation estocástico y aproximada
Inferencia en modelos generativos profundas. Informe técnico, arXiv: 1401.4082.

[25] Rifai, S., Bengio, Y., Dauphin, Y., y Vincent, P. (2012). Un proceso generativo para el muestreo de contracción
auto-codificadores. En ICML’/ 2.

[26] Salakhutdinov, R. y Hinton, G. E. (2009). máquinas profunda Boltzmann. En AISTATS'2009, páginas 448--
455.

[27] Smolensky, P. (1986). procesamiento de la información en los sistemas dinámicos: Fundamentos de la teoría de la armonía. En
D. E. Rumelhart y McClelland J. L., editores, distribuido paralelo Processing, volumen 1, capítulo 6, páginas
194-281. MIT Press, Cambridge.

[28] Susskind, J., Anderson, A., y Hinton, G. E. (2010). La cara conjunto de datos de Toronto. Informe Técnico UTML
TR 2010-001, U. de Toronto.

[29] Tieleman, T. (2008). El entrenamiento de máquinas de Boltzmann restringidas utilizando aproximaciones a la probabilidad
degradado. En W. W. Cohen, A. McCallum, y S. T. Roweis, editores, ICML 2008, páginas 1064-1071. ACM.

[30] Vicente, P., Larochelle, H., Bengio, Y., y Manzagol, P.-A. (2008). La extracción y la composición robusta
cuenta con autoencoders eliminación de ruido. En ICML 2008.

[31] Younes, L. (1999). En la convergencia de los algoritmos estocásticos de Markov a medida que disminuye rápidamente
Ergodicidad tasas. Estocástica y estocástico Reports, 65 (3), 177-228.