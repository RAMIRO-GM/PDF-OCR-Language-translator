{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this tutorial you will generate a .txt file translated given a pdf file in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 \n",
    "import pytesseract\n",
    "import pyocr\n",
    "import pyocr.builders\n",
    "from PIL import Image \n",
    "import sys \n",
    "from pdf2image import convert_from_path \n",
    "import os \n",
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "#from wand.image import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert pdf to images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path of the pdf \n",
    "PDF_file = \"gans.pdf\"\n",
    "\n",
    "  \n",
    "# Store all the pages of the PDF in a variable \n",
    "pages = convert_from_path(PDF_file, 500) \n",
    "\n",
    " \n",
    "# Counter to store images of each page of PDF to image \n",
    "image_counter = 1\n",
    "  \n",
    "# Iterate through all the pages stored above \n",
    "for page in pages: \n",
    "  \n",
    "    # Declaring filename for each page of PDF as JPG \n",
    "    # For each page, filename will be: \n",
    "    # PDF page 1 -> page_1.jpg \n",
    "    # PDF page 2 -> page_2.jpg \n",
    "    # PDF page 3 -> page_3.jpg \n",
    "    # .... \n",
    "    # PDF page n -> page_n.jpg \n",
    "    filename = \"page_\"+str(image_counter)+\".jpg\"\n",
    "      \n",
    "    # Save the image of the page in system \n",
    "    page.save(filename, 'JPEG') \n",
    "  \n",
    "    # Increment the counter to update filename \n",
    "    image_counter = image_counter + 1\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at your folder, there must be .jpg images from the pdf "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's start using [googletrans](https://py-googletrans.readthedocs.io/en/latest/) in python\n",
    "## Example using the traslator given some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected(lang=ko, confidence=1.0)\n",
      "¿Hola como estas? I ha sido un largo camino de vuelta a casa\n"
     ]
    }
   ],
   "source": [
    "text = 'Hello, how are you? I has been a long way back home'\n",
    "print(translator.detect('이 문장은 한글로 쓰여졌습니다.'))\n",
    "spa_trans = translator.translate(text, src='en',dest='es')\n",
    "#print(translator.translate(text, src='en',dest='es'))\n",
    "print(spa_trans.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's use Tesseract in an image and see the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This framework can yield specific training algorithms for many kinds of model and optimization\n",
      "algorithm. In this article, we explore the special case when the generative model generates samples\n",
      "by passing random noise through a multilayer perceptron, and the discriminative model is also a\n",
      "multilayer perceptron. We refer to this special case as adversarial nets. In this case, we can train\n",
      "both models using only the highly successful backpropagation and dropout algorithms [17] and\n",
      "sample from the generative model using only forward propagation. No approximate inference or\n",
      "Markov chains are necessary.\n",
      "\n",
      "2 Related work\n",
      "\n",
      "An alternative to directed graphical models with latent variables are undirected graphical models\n",
      "with latent variables, such as restricted Boltzmann machines (RBMs) [27, 16], deep Boltzmann\n",
      "machines (DBMs) [26] and their numerous variants. The interactions within such models are\n",
      "represented as the product of unnormalized potential functions, normalized by a global summation/integration over all states of the random variables. This quantity (the partition function) and\n",
      "its gradient are intractable for all but the most trivial instances, although they can be estimated by\n",
      "Markov chain Monte Carlo (MCMC) methods. Mixing poses a significant problem for learning\n",
      "algorithms that rely on MCMC (3, 5].\n",
      "\n",
      "Deep belief networks (DBNs) [16] are hybrid models containing a single undirected layer and several directed layers. While a fast approximate layer-wise training criterion exists, DBNs incur the\n",
      "computational difficulties associated with both undirected and directed models.\n",
      "\n",
      "Alternative criteria that do not approximate or bound the log-likelihood have also been proposed,\n",
      "such as score matching [18] and noise-contrastive estimation (NCE) [13]. Both of these require the\n",
      "learned probability density to be analytically specified up to a normalization constant. Note that\n",
      "in many interesting generative models with several layers of latent variables (such as DBNs and\n",
      "DBMs), it is not even possible to derive a tractable unnormalized probability density. Some models\n",
      "such as denoising auto-encoders [30] and contractive autoencoders have learning rules very similar\n",
      "to score matching applied to RBMs. In NCE, as in this work, a discriminative training criterion is\n",
      "employed to fit a generative model. However, rather than fitting a separate discriminative model, the\n",
      "generative model itself is used to discriminate generated data from samples a fixed noise distribution.\n",
      "Because NCE uses a fixed noise distribution, learning slows dramatically after the model has learned\n",
      "even an approximately correct distribution over a small subset of the observed variables.\n",
      "\n",
      "Finally, some techniques do not involve defining a probability distribution explicitly, but rather train\n",
      "a generative machine to draw samples from the desired distribution. This approach has the advantage\n",
      "that such machines can be designed to be trained by back-propagation. Prominent recent work in this\n",
      "area includes the generative stochastic network (GSN) framework [5], which extends generalized\n",
      "denoising auto-encoders [4]: both can be seen as defining a parameterized Markov chain, i.e., one\n",
      "learns the parameters of a machine that performs one step of a generative Markov chain. Compared\n",
      "to GSNs, the adversarial nets framework does not require a Markov chain for sampling. Because\n",
      "adversarial nets do not require feedback loops during generation, they are better able to leverage\n",
      "piecewise linear units [19, 9, 10], which improve the performance of backpropagation but have\n",
      "problems with unbounded activation when used ina feedback loop. More recent examples of training\n",
      "a generative machine by back-propagating into it include recent work on auto-encoding variational\n",
      "Bayes [20] and stochastic backpropagation [24].\n",
      "\n",
      "3  Adversarial nets\n",
      "\n",
      "The adversarial modeling framework is most straightforward to apply when the models are both\n",
      "multilayer perceptrons. To learn the generator’s distribution p, over data x, we define a prior on\n",
      "input noise variables p,(z), then represent a mapping to data space as G(z;6,), where G' is a\n",
      "differentiable function represented by a multilayer perceptron with parameters 6,. We also define a\n",
      "second multilayer perceptron D(x; 6,) that outputs a single scalar. D(a) represents the probability\n",
      "that x came from the data rather than pg. We train D to maximize the probability of assigning the\n",
      "correct label to both training examples and samples from G. We simultaneously train G to minimize\n",
      "log(1 — D(G(z))):\n"
     ]
    }
   ],
   "source": [
    "text = pytesseract.image_to_string(cv2.imread('page_2.jpg'))\n",
    "text = text.replace('-\\n', '')\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of the previous generated text translated into Spanish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[en:0.9999955035469207]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identifying the language\n",
    "from langdetect import detect_langs\n",
    "detect_langs(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Este marco puede producir algoritmos específicos de formación para muchos tipos de modelo y optimización\n",
      "algoritmo. En este artículo se analiza el caso especial cuando el modelo generativo genera muestras\n",
      "haciendo pasar el ruido aleatorio a través de un perceptrón de múltiples capas, y el modelo discriminativo es también una\n",
      "perceptrón multicapa. Nos referimos a este caso especial como redes de confrontación. En este caso, podemos entrenar\n",
      "ambos modelos usando sólo el backpropagation gran éxito y algoritmos de deserción [17] y\n",
      "muestra desde el modelo generativo utilizando sólo propagación hacia adelante. No inferencia aproximada o\n",
      "Las cadenas de Markov son necesarios.\n",
      "\n",
      "2. Trabajo relacionado\n",
      "\n",
      "Una alternativa a modelos gráficos dirigidos con variables latentes están no dirigidos modelos gráficos\n",
      "con variables latentes, tales como máquinas de Boltzmann restringidos (RBM) [27, 16], en el fondo Boltzmann\n",
      "máquinas (DBMS) [26] y sus numerosas variantes. Las interacciones dentro de tales modelos son\n",
      "representada como el producto de funciones potenciales no normalizadas, normalizado por una suma / integración global sobre todos los estados de las variables aleatorias. Esta cantidad (la función de partición) y\n",
      "su gradiente son intratables para todos, pero la mayoría de los casos triviales, aunque pueden ser estimados\n",
      "la cadena de Markov Monte Carlo (MCMC) métodos. Mezcla plantea un problema importante para el aprendizaje\n",
      "Los algoritmos que se basan en MCMC (3, 5].\n",
      "\n",
      "redes de creencias profundas (DBNs) [16] son ​​modelos híbridos que contienen una sola capa no dirigido y varias capas dirigidas. Si bien existe un criterio de formación por capas rápida aproximada, incurren en la DBNs\n",
      "dificultades de cálculo asociados con ambos modelos no dirigida y dirigida.\n",
      "\n",
      "criterios alternativos que no lo hacen aproximada o unido al también han sido propuestos de probabilidad logarítmica,\n",
      "tales como puntuación de coincidencia [18] y la estimación de ruido-contrastivo (NCE) [13]. Ambos requieren la\n",
      "densidad de probabilidad aprendido a ser especificado analíticamente hasta una constante de normalización. Tenga en cuenta que\n",
      "en muchos modelos generativos interesantes con varias capas de variables latentes (como DBNs y\n",
      "DBMS), ni siquiera es posible derivar una densidad de probabilidad no normalizada tratable. algunos modelos\n",
      "como autoencoders eliminación de ruido [30] y autoencoders contractivas tienen reglas muy similares aprendizaje\n",
      "de puntuación de adaptación aplicado a los mismos mecanismos. En NCE, como en este trabajo, un criterio de entrenamiento discriminativo es\n",
      "empleado para ajustar un modelo generativo. Sin embargo, en lugar de ajustar un modelo discriminativo independiente, la\n",
      "propio modelo generativo se usa para discriminar datos generados a partir de muestras de una distribución de ruido fijo.\n",
      "Debido a NCE utiliza una distribución de ruido fijo, disminuye drásticamente después de aprender el modelo ha aprendido\n",
      "incluso una distribución aproximadamente correcta sobre un pequeño subconjunto de las variables observadas.\n",
      "\n",
      "Por último, algunas técnicas no implican la definición de una distribución de probabilidad de manera explícita, sino que entrenan\n",
      "una máquina generativo para extraer muestras a partir de la distribución deseada. Este enfoque tiene la ventaja\n",
      "que tales máquinas pueden ser diseñados para ser entrenado por retropropagación. el trabajo reciente más importante en este\n",
      "área incluye la red estocástico generativa (GSN) marco [5], que se extiende generalizarse\n",
      "eliminación de ruido auto-codificadores [4]: ​​ambas pueden ser vistas como la definición de una cadena de Markov parametrizado, es decir, uno\n",
      "aprende los parámetros de una máquina que realiza un paso de una cadena de Markov generativo. Comparado\n",
      "a GSN, el marco de las redes de confrontación no requiere una cadena de Markov para el muestreo. Porque\n",
      "redes de confrontación no requieren circuitos de retroalimentación durante la generación, están en mejores condiciones de apalancamiento\n",
      "unidades lineales por partes [19, 9, 10], que mejoran el rendimiento de backpropagation pero tienen\n",
      "problemas con la activación sin límites cuando se utiliza ina bucle de realimentación. Más ejemplos recientes de la formación\n",
      "una máquina generadora por propagan hacia atrás en ella incluyen trabajos recientes sobre variacional de auto-codificación\n",
      "Bayes [20] y backpropagation estocástico [24].\n",
      "\n",
      "3 redes Acusatorios\n",
      "\n",
      "El marco de modelado de confrontación es más sencillo de aplicar cuando los modelos son a la vez\n",
      "perceptrones multicapa. Para conocer la distribución P del generador, a través de datos X, definimos un sobre antes\n",
      "de entrada variables de ruido p, (z), entonces representa una asignación a espacio de datos como G (z; 6,), donde G' es una\n",
      "función diferenciable representado por un perceptrón multicapa con parámetros 6 ,. También definimos una\n",
      "segundo perceptrón multicapa D (x; 6,) que da salida a un solo escalar. D (a) representa la probabilidad\n",
      "x que vinieron de los datos en lugar de PG. Formamos a D para maximizar la probabilidad de que la asignación de la\n",
      "correcta etiqueta para ambos ejemplos de entrenamiento y muestras de G. Nos entrenamos simultáneamente G para minimizar\n",
      "log (1 - D (G (z))):\n"
     ]
    }
   ],
   "source": [
    "# Once the language is identified: Translate\n",
    "spanish_translation = translator.translate(text, src='en',dest='es')\n",
    "print(spanish_translation.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Iterate over all images and generate the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully translated:  page_1.jpg\n",
      "Successfully translated:  page_2.jpg\n",
      "Successfully translated:  page_3.jpg\n",
      "Successfully translated:  page_4.jpg\n",
      "Successfully translated:  page_5.jpg\n",
      "Successfully translated:  page_6.jpg\n",
      "Successfully translated:  page_7.jpg\n",
      "Successfully translated:  page_8.jpg\n",
      "Successfully translated:  page_9.jpg\n"
     ]
    }
   ],
   "source": [
    "''' \n",
    "Part #2 - Recognizing text from the images using OCR \n",
    "'''\n",
    "    \n",
    "# Variable to get count of total number of pages \n",
    "filelimit = image_counter-1\n",
    "  \n",
    "# Creating a text file to write the output \n",
    " \n",
    "# Open the file in append mode so that  \n",
    "# All contents of all images are added to the same file \n",
    "with open('out_translated_text.txt', 'w', encoding='utf-8') as f:\n",
    "  \n",
    "     # Iterate from 1 to total number of pages \n",
    "    for i in range(1, filelimit + 1): \n",
    "\n",
    "        # Set filename to recognize text from \n",
    "        # Again, these files will be: \n",
    "        # page_1.jpg \n",
    "        # page_2.jpg \n",
    "        # .... \n",
    "        # page_n.jpg \n",
    "        filename = \"page_\"+str(i)+\".jpg\"\n",
    "\n",
    "        # Recognize the text as string in image using pytesserct \n",
    "        text = str(((pytesseract.image_to_string(Image.open(filename))))) \n",
    "\n",
    "        # The recognized text is stored in variable text \n",
    "        # Any string processing may be applied on text \n",
    "        # Here, basic formatting has been done: \n",
    "        # In many PDFs, at line ending, if a word can't \n",
    "        # be written fully, a 'hyphen' is added. \n",
    "        # The rest of the word is written in the next line \n",
    "        # Eg: This is a sample text this word here GeeksF- \n",
    "        # orGeeks is half on first line, remaining on next. \n",
    "        # To remove this, we replace every '-\\n' to ''. \n",
    "        text = text.replace('-\\n', '')     \n",
    "        spa_trans = translator.translate(text, src='en',dest='es')\n",
    "        f.write(spa_trans.text) \n",
    "        print('Successfully translated: ',filename)\n",
    "        # Finally, write the processed text to the file. \n",
    "        #f.write(text) \n",
    "\n",
    "        # Close the file after writing all the text. \n",
    "f.close() \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the output text file generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406.266lv1 [stat ML] 10 de junio 2014\n",
      "\n",
      "mi\n",
      "mi\n",
      "\n",
      "ar X1Vv\n",
      "\n",
      " \n",
      "\n",
      "Redes generativas adversarias\n",
      "\n",
      "Ian J. Goodfellow, Jean Pouget-Abadie; Mehdi Mirza, Bing Xu, David Warde-Farley,\n",
      "Sherjil Ozair! Aaron Courville, Yoshua Bengio *\n",
      "Departamento d’Informatique et de recherche opérationnelle\n",
      "\n",
      "Universidad de Montreal\n",
      "Montreal, QC H3C 3J7\n",
      "\n",
      "Resumen\n",
      "\n",
      "Se propone un nuevo marco para la estimación de los modelos generativos a través de un proceso contradictorio, en el que al mismo tiempo entrenamos dos modelos: un modelo generativo G\n",
      "que captura la distribución de datos, y un modelo discriminativo D que las estimaciones\n",
      "la probabilidad de que una muestra de vino de los datos de entrenamiento en lugar de G. El procedimiento de entrenamiento para G' es maximizar la probabilidad de cometer un error D. Esta\n",
      "marco corresponde a un Minimax juego de dos jugadores. En el espacio de arbitraria\n",
      "funciones G y D, existe una solución única, con G recuperación de los datos de entrenamiento\n",
      "distribución y D igual a 5 en todas partes. En el caso donde se definen G y D\n",
      "por perceptrones multicapa, todo el sistema puede ser entrenado con propagación hacia atrás.\n",
      "No hay necesidad de ningún cadenas de Markov o redes de inferencia aproximados desenrollados durante entrenamiento o generación de muestras. Los experimentos demuestran\n",
      "el potencial del marco mediante una evaluación cualitativa y cuantitativa de\n",
      "las muestras generadas.\n",
      "\n",
      "1. Introducción\n",
      "\n",
      "La promesa de aprendizaje profundo es descubrir los modelos jerárquicos ricos, [2] que representan la probabilidad\n",
      "distribuciones más de los tipos de datos se encuentran en aplicaciones de inteligencia artificial, como naturales\n",
      "imágenes, formas de onda de audio que contiene voz y símbolos en los corpus de lenguaje natural. Hasta ahora, el\n",
      "la mayoría de los éxitos notables en el aprendizaje profundo tienen modelos discriminativos involucradas, por lo general aquellas que\n",
      "asignar una entrada sensorial de alta dimensión, rica a una etiqueta de clase [14, 22]. Estos éxitos sorprendentes tienen\n",
      "principalmente ha basado en los algoritmos de retropropagación y deserción, utilizando lineal a trozos unidades\n",
      "[19, 9, 10], que tiene un gradiente particular de buen comportamiento. modelos generativos profundos han tenido menos\n",
      "de un impacto, debido a la dificultad de la aproximación de muchos cálculos probabilísticos que intratables\n",
      "surgir en estimación de máxima verosimilitud y estrategias relacionadas, y debido a la dificultad de apalancamiento\n",
      "los beneficios de trozos lineales de unidades en el contexto generativo. Proponemos un nuevo modelo generativo\n",
      "procedimiento de estimación que deja de lado estas dificultades. !\n",
      "\n",
      "En el marco redes contradictorio propuesto, el modelo generativo se enfrenta a un adversario: una\n",
      "modelo discriminativo que aprende para determinar si una muestra es de la distribución de modelo o de la\n",
      "distribución de datos. El modelo generativo puede ser pensado como algo análogo a un equipo de falsificadores,\n",
      "tratando de producir moneda falsa y utilizarlo sin detección, mientras que el modelo es discriminativo\n",
      "análoga a la policía, tratando de detectar la falsificación de moneda. La competencia en este juego drives\n",
      "Ambos equipos para mejorar sus métodos hasta que las falsificaciones son indistiguishable de la genuina\n",
      "artículos.\n",
      "\n",
      "“Jean-Pouget Abadie está de visita en la Universidad de Montreal de la Escuela Politécnica.\n",
      "\n",
      "'Sherjil Ozair está de visita en la Universidad de Montreal, del Instituto Indio de Tecnología de Delhi\n",
      "\n",
      "* Yoshua Bengio es un CIFAR Senior Fellow.\n",
      "\n",
      "'Todo el código y hiperparámetros disponible en http: //www.github.com/goodfeli/adversarialEste marco puede producir algoritmos específicos de formación para muchos tipos de modelo y optimización\n",
      "algoritmo. En este artículo se analiza el caso especial cuando el modelo generativo genera muestras\n",
      "haciendo pasar el ruido aleatorio a través de un perceptrón de múltiples capas, y el modelo discriminativo es también una\n",
      "perceptrón multicapa. Nos referimos a este caso especial como redes de confrontación. En este caso, podemos entrenar\n",
      "ambos modelos usando sólo el backpropagation gran éxito y algoritmos de deserción [17] y\n",
      "muestra desde el modelo generativo utilizando sólo propagación hacia adelante. No inferencia aproximada o\n",
      "Las cadenas de Markov son necesarios.\n",
      "\n",
      "2. Trabajo relacionado\n",
      "\n",
      "Una alternativa a modelos gráficos dirigidos con variables latentes están no dirigidos modelos gráficos\n",
      "con variables latentes, tales como máquinas de Boltzmann restringidos (RBM) [27, 16], en el fondo Boltzmann\n",
      "máquinas (DBMS) [26] y sus numerosas variantes. Las interacciones dentro de tales modelos son\n",
      "representada como el producto de funciones potenciales no normalizadas, normalizado por una suma / integración global sobre todos los estados de las variables aleatorias. Esta cantidad (la función de partición) y\n",
      "su gradiente son intratables para todos, pero la mayoría de los casos triviales, aunque pueden ser estimados\n",
      "la cadena de Markov Monte Carlo (MCMC) métodos. Mezcla plantea un problema importante para el aprendizaje\n",
      "Los algoritmos que se basan en MCMC (3, 5].\n",
      "\n",
      "redes de creencias profundas (DBNs) [16] son ​​modelos híbridos que contienen una sola capa no dirigido y varias capas dirigidas. Si bien existe un criterio de formación por capas rápida aproximada, incurren en la DBNs\n",
      "dificultades de cálculo asociados con ambos modelos no dirigida y dirigida.\n",
      "\n",
      "criterios alternativos que no lo hacen aproximada o unido al también han sido propuestos de probabilidad logarítmica,\n",
      "tales como puntuación de coincidencia [18] y la estimación de ruido-contrastivo (NCE) [13]. Ambos requieren la\n",
      "densidad de probabilidad aprendido a ser especificado analíticamente hasta una constante de normalización. Tenga en cuenta que\n",
      "en muchos modelos generativos interesantes con varias capas de variables latentes (como DBNs y\n",
      "DBMS), ni siquiera es posible derivar una densidad de probabilidad no normalizada tratable. algunos modelos\n",
      "como autoencoders eliminación de ruido [30] y autoencoders contractivas tienen reglas muy similares aprendizaje\n",
      "de puntuación de adaptación aplicado a los mismos mecanismos. En NCE, como en este trabajo, un criterio de entrenamiento discriminativo es\n",
      "empleado para ajustar un modelo generativo. Sin embargo, en lugar de ajustar un modelo discriminativo independiente, la\n",
      "propio modelo generativo se usa para discriminar datos generados a partir de muestras de una distribución de ruido fijo.\n",
      "Debido a NCE utiliza una distribución de ruido fijo, disminuye drásticamente después de aprender el modelo ha aprendido\n",
      "incluso una distribución aproximadamente correcta sobre un pequeño subconjunto de las variables observadas.\n",
      "\n",
      "Por último, algunas técnicas no implican la definición de una distribución de probabilidad de manera explícita, sino que entrenan\n",
      "una máquina generativo para extraer muestras a partir de la distribución deseada. Este enfoque tiene la ventaja\n",
      "que tales máquinas pueden ser diseñados para ser entrenado por retropropagación. el trabajo reciente más importante en este\n",
      "área incluye la red estocástico generativa (GSN) marco [5], que se extiende generalizarse\n",
      "eliminación de ruido auto-codificadores [4]: ​​ambas pueden ser vistas como la definición de una cadena de Markov parametrizado, es decir, uno\n",
      "aprende los parámetros de una máquina que realiza un paso de una cadena de Markov generativo. Comparado\n",
      "a GSN, el marco de las redes de confrontación no requiere una cadena de Markov para el muestreo. Porque\n",
      "redes de confrontación no requieren circuitos de retroalimentación durante la generación, están en mejores condiciones de apalancamiento\n",
      "unidades lineales por partes [19, 9, 10], que mejoran el rendimiento de backpropagation pero tienen\n",
      "problemas con la activación sin límites cuando se utiliza ina bucle de realimentación. Más ejemplos recientes de la formación\n",
      "una máquina generadora por propagan hacia atrás en ella incluyen trabajos recientes sobre variacional de auto-codificación\n",
      "Bayes [20] y backpropagation estocástico [24].\n",
      "\n",
      "3 redes Acusatorios\n",
      "\n",
      "El marco de modelado de confrontación es más sencillo de aplicar cuando los modelos son a la vez\n",
      "perceptrones multicapa. Para conocer la distribución P del generador, a través de datos X, definimos un sobre antes\n",
      "de entrada variables de ruido p, (z), entonces representa una asignación a espacio de datos como G (z; 6,), donde G' es una\n",
      "función diferenciable representado por un perceptrón multicapa con parámetros 6 ,. También definimos una\n",
      "segundo perceptrón multicapa D (x; 6,) que da salida a un solo escalar. D (a) representa la probabilidad\n",
      "x que vinieron de los datos en lugar de PG. Formamos a D para maximizar la probabilidad de que la asignación de la\n",
      "correcta etiqueta para ambos ejemplos de entrenamiento y muestras de G. Nos entrenamos simultáneamente G para minimizar\n",
      "log (1 - D (G (z))):En otras palabras, D y G juegan el siguiente juego minimax de dos jugadores con función de valor V (G, D):\n",
      "\n",
      "min max V (D, G) = Eanpaa (x) (log D (@)] + Eznp, (z) [log (1 -. D (G (z)))] (1)\n",
      "\n",
      "En la siguiente sección, se presenta un análisis teórico de las redes de confrontación, esencialmente mostrando que\n",
      "el criterio de formación permite a uno para recuperar la distribución de generación de datos como se dan G y D\n",
      "suficiente capacidad, 1.e, en el límite no paramétrico. Ver Figura | para un menos formal, más pedagógico\n",
      "explicación del enfoque. En la práctica, debemos poner en práctica el juego usando un proceso iterativo, numérica\n",
      "Acercarse. Optimización D hasta su finalización en el bucle interno de la formación es computacionalmente prohibitivo,\n",
      "y en conjuntos de datos finitos daría lugar a un ajuste por exceso. En su lugar, se alternan entre k pasos de optimización\n",
      "D y un paso de optimizar los resultados G. esto en D se mantienen cerca de su solución óptima, por lo\n",
      "siempre y cuando G cambia lentamente suficiente. Esta estrategia es análoga a la forma en que SML / PCD [31, 29]\n",
      "formación mantiene muestras de una cadena de Markov de un paso de aprendizaje a la siguiente con el fin de evitar\n",
      "ardor en una cadena de Markov como parte del bucle interior de aprendizaje. El procedimiento se presenta formalmente\n",
      "en el algoritmo 1.\n",
      "\n",
      "En la práctica, la ecuación 1 puede no proporcionar gradiente suficiente para G para aprender bien. A principios de aprendizaje,\n",
      "cuando G es pobre, D puede rechazar muestras con alta confianza, ya que son claramente diferentes de\n",
      "los datos de entrenamiento. En este caso, log (1 - D ()) Z G () se satura. En lugar de la formación de G para minimizar\n",
      "log (1 - D (G (z))) podemos entrenar G para maximizar log D (G (z)). Esta función objetivo se traduce en la\n",
      "mismo punto fijo de la dinámica de G y D, pero ofrece mucho más fuertes gradientes temprano en el aprendizaje.\n",
      "\n",
      "  \n",
      "\n",
      "   \n",
      "\n",
      "  \n",
      "\n",
      "s\n",
      "e e\n",
      "\n",
      "‘s\n",
      "- N / A .\n",
      "’Ae.\n",
      ".\n",
      ".\n",
      "y\n",
      "e e\n",
      "‘\n",
      "y\n",
      "mi\n",
      ".\n",
      ".\n",
      "4 eee\n",
      "@ ® fy ‘\n",
      "+ @ 18, =\n",
      "wae una\n",
      "La SY\n",
      "\n",
      "(a B C D)\n",
      "\n",
      "Figura 1: Redes de confrontación generativos son entrenados por actualizar simultáneamente la distribución discriminativo\n",
      "(D, azul, línea discontinua) de modo que discrimina entre las muestras de la distribución de generación de datos (negro,\n",
      "línea de puntos) pz de los de la distribución pg generativa (G) (verde, línea sólida). La línea horizontal inferior es\n",
      "el dominio desde el que z es muestreada, en este caso de manera uniforme. La línea horizontal arriba es parte del dominio\n",
      "de un. Las flechas hacia arriba muestran cómo el mapeo a = G (z) aplica la distribución de p no uniforme, en\n",
      "muestras transformadas. G contrae en regiones de alta densidad y se expande en las regiones de baja densidad de pg. (una)\n",
      "Consideremos un par de adversarios cerca de la convergencia: PG es similar a los datos y D es un clasificador parcialmente exacta.\n",
      "(B) En el bucle interno del algoritmo D está capacitado para muestras diferenciar de datos, convergiendo a D * (x) =\n",
      "SNS (c) Después de una actualización de G, gradiente de D ha guiado G (z) fluya a las regiones que tienen más probabilidades\n",
      "para ser clasificado como de datos. (D) Después de varias etapas de formación, si G y D tienen capacidad suficiente, van a llegar a una\n",
      "punto en el que ambos no pueden mejorar porque pg = Paata. El discriminador es incapaz de diferenciar entre\n",
      "\n",
      "las dos distribuciones, es decir. D (a) = $ 5.\n",
      "\n",
      "4 resultados teóricos\n",
      "\n",
      "El generador G' define implícitamente una distribución de probabilidad p, como la distribución de las muestras\n",
      "G (z) obtiene cuando z ~ pz. Por lo tanto, nos gustaría Algoritmo 1 a converger a un buen estimador\n",
      "De Paata, 1F dado suficiente capacidad y tiempo de entrenamiento. Los resultados de esta sección se realizan en un entorno no paramétrico, por ejemplo representamos un modelo con capacidad infinita mediante el estudio de la convergencia en el\n",
      "espacio de las funciones de densidad de probabilidad.\n",
      "\n",
      "Vamos a mostrar en la sección 4.1 que este juego Minimax tiene un óptimo global para PG = Pdata. Lo haremos\n",
      "a continuación, mostrar en la sección 4.2 que el algoritmo | optimiza la ecuación 1, obteniendo así el resultado deseado.Algoritmo 1 Minibatch formación estocástico pendiente de descenso de las redes adversarias generativos. El número de\n",
      "Pasos para aplicar al discriminador, k, es una hiperparámetro. Utilizamos k = 1, la opción menos costosa, en nuestra\n",
      "experimentos.\n",
      "para el número de iteraciones de entrenamiento hacer\n",
      "para k pasos hacen\n",
      "\n",
      "e minibatch de muestra de las muestras de ruido m {z, ..., 2 °} de p ruido antes, (z).\n",
      "e minibatch de muestra de m ejemplos Fe), Ley ap) de distribución de generación de datos\n",
      "Paata (2).\n",
      "\n",
      "e Actualizar el discriminador ascendiendo su gradiente estocástico:\n",
      "\n",
      "Voe ~>. [Log D (2) + 10 ¢ (1 - D (E (2)))).\n",
      "\n",
      "wl\n",
      "\n",
      "para terminar\n",
      "e minibatch de muestra de las muestras de ruido m {z “), ..., 2} de py ruido antes (z).\n",
      "e actualización del generador al descender de su gradiente estocástico:\n",
      "\n",
      "Vor Yates (I ~ (@ (2))).\n",
      "\n",
      "para terminar\n",
      "Las actualizaciones basadas en gradiente pueden utilizar cualquier regla estándar aprendizaje basado en el gradiente. Utilizamos impulso en nuestros experimentos.\n",
      "\n",
      " \n",
      "\n",
      "4.1 Global optimalidad de p, = Paata\n",
      "Consideramos en primer lugar la óptima discriminador D para cualquier generador dada G.\n",
      "Propuesta 1. Para G fijo, el óptimo discriminador D es\n",
      "\n",
      "SE __ Paata (X)\n",
      "Data) = Paata (®) + Pg (2) *)\n",
      "\n",
      "Prueba. El criterio de formación para el discriminador D, teniendo en cuenta cualquier generador G, es maximizar el\n",
      "cantidad V (G, D)\n",
      "\n",
      "V (G, D) = / pAAA () log (D (a)) dx + / p2 (z) log (1 - D (g (z))) dz\n",
      "\n",
      "WV z\n",
      "\n",
      "= / PAAA (a @) log (D (a)) + pg (a) log (1 - D (a)) da (3)\n",
      "\n",
      "Para cualquier (a, b) R €? \\ {0,0}, la función y> álogo (y) + diario (1 - y) alcanza su máximo en\n",
      "[0, 1] a <5. El discriminador no tiene que ser definida fuera de Sop (Pdata) U Sop (PQ),\n",
      "la conclusión de la prueba. LJ\n",
      "\n",
      "Tenga en cuenta que el objetivo de entrenamiento para D puede interpretarse como maximizar el diario de probabilidad para estimar la probabilidad condicional P (Y = y | a), donde Y indica si x viene de Paata\n",
      "(Con y = 1) o desde pg (con y = 0). El juego Minimax en la ecuación. 1 ahora se puede reformular como:\n",
      "\n",
      "C (G) = V max (G, D)\n",
      "Bev puallog Di, (a)] + Exxp, [log (1 - DE (G (2))) (4)\n",
      "= Ej ~ registro de ping DG (x)] + Ex ~ p, [log (1 - DG (x))]\n",
      "\n",
      "Pdata (a) | Dg ()\n",
      "= Exxpi, registro = e + - | + Eany, [log - ~ 2 4+ -_\n",
      "° ° Paata (£) + Pg (x) ns ° Paata (X) + Dg (x)Teorema 1. El mínimo global del criterio de la formación virtual C (G) se logra si y sólo si\n",
      "Pg = Paata. En ese punto, CG) alcanza el valor - log 4.\n",
      "\n",
      "5? nosotros\n",
      "encontrar C (G) = log 4 + log $ = - log 4. Para ver que este es el mejor valor posible de C (G), alcanzado\n",
      "sólo para py = Paata, observar que\n",
      "\n",
      "Prueba. Para pg = PDAA, D (x) = 5, (considerar. Eq 2). Por lo tanto, mediante la inspección de la ecuación. 4 en el DE, (x) = 4\n",
      "\n",
      "Kew pana [- log 2] + EXNP, [-log 2] = - log 4\n",
      "y que restando esta expresión de C '(G’)) = V (D &, G), se obtiene:\n",
      "\n",
      "C (Q) = -log (4) + KL (como (5)\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Pd a + p\n",
      "Ss t) enn (n,\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Pdata + P g\n",
      "2\n",
      "\n",
      "donde KL es la divergencia de Kullback-Leibler. Reconocemos en la expresión anterior el Jensen-\n",
      "divergencia Shannon entre la distribución del modelo y el proceso de generación de datos:\n",
      "\n",
      "C (@) = -log (4) 2 ISD (PASA || P) 6)\n",
      "\n",
      "Desde la divergencia Jensen-Shannon entre dos distribuciones es siempre no negativa y cero\n",
      "solamente cuando son iguales, hemos demostrado que C * = - log (4) es el mínimo global de C '(G) y\n",
      "que la única solución es py = Pdata, 1. €., el modelo generativo perfectamente replicar la generación de datos de\n",
      "proceso. L\n",
      "\n",
      "4.2 Convergencia del algoritmo 1\n",
      "\n",
      "Proposición 2. IfG y D tienen suficiente capacidad, y en cada paso del algoritmo I, el discriminador\n",
      "se le permite alcanzar su óptima dada G, y PG se actualiza a fin de mejorar el criterio\n",
      "\n",
      "Fenian registro de DE (x)] + Ex ~ p, [log (1 - DG (x))]\n",
      "\n",
      "converge entonces pg a DDATA\n",
      "\n",
      "Prueba. Considere V (G, D) = U (pg, D) como una función de pg como hecho en el criterio anterior. Nota\n",
      "que U (p ,, D) es convexa en p ,. Los subderivatives de un extremo superior de funciones convexas incluyen la\n",
      "derivada de la función en el punto donde se alcanza el máximo. En otras palabras, si f (a) =\n",
      "supgca fa (x) y f (x) es convexa en x para cada una, a continuación, OFG (x) € De si 6 = argsupyey fa (Z).\n",
      "Esto es equivalente a calcular una actualización de descenso de gradiente para p, en el óptimo D dada la correspondiente G .. supp U (p ,, D) es convexa en pg con una optima global única como probados en Thm 1,\n",
      "por lo tanto, con suficientemente pequeñas actualizaciones de pg, p, converge a p ;, finales la prueba. |\n",
      "\n",
      " \n",
      "\n",
      "En la práctica, las redes de confrontación representan una familia limitado de p, distribuciones a través de la función G (z; 6,),\n",
      "y optimizamos 6, en lugar de en sí pg. El uso de un perceptrón multicapa para definir G introduce\n",
      "múltiples puntos críticos en el espacio de parámetros. Sin embargo, el excelente desempeño de múltiples capas perceptrones en la práctica sugiere que son un modelo razonable para el uso a pesar de su falta de teórico\n",
      "garantías.\n",
      "\n",
      "5 experimentos\n",
      "\n",
      "Hemos capacitado a las redes adversarias una una serie de conjuntos de datos incluyendo MNIST [23], la base de datos de Toronto de la cara\n",
      "(TFD) [28], y CIFAR-10 [21]. Las redes de generador utilizado una mezcla de activaciones lineales rectificador [19,\n",
      "9] y activaciones sigmoideas, mientras que el discriminador MAXOUT usado neto [10] activaciones. Dropout [17]\n",
      "se aplicó en el entrenamiento de la red discriminador. Si bien nuestro marco teórico permite el uso de\n",
      "deserción y otros ruidos en las capas intermedias de la generador, hemos utilizado el ruido como la entrada a solamente\n",
      "la capa inferior de la red del generador.\n",
      "\n",
      "Estimamos la probabilidad de los datos del conjunto de prueba bajo p, mediante la instalación de una ventana de Gauss a la Parzen\n",
      "muestras generadas con G y que informan de la probabilidad log-bajo esta distribución. El parámetro omodelo | MNIST TFD\n",
      "DBN [3] 138 2 1,909 + 66\n",
      "Stacked CAE [3] | 121 + 1,6 | 2110 + 50\n",
      "Profunda GSN [6] 214 + 1,1 | 1890 + 29\n",
      "redes de confrontación 225 + 2 | 2057 + 26\n",
      "\n",
      " \n",
      "\n",
      "Tabla 1: estimaciones de probabilidad logarítmica basados ​​en ventanas de Parzen. Los números reportados en MNIST son los loglikelihood media de las muestras en la prueba de conjunto, con el error estándar de la media calculada a través de ejemplos. En TFD, nos\n",
      "calculado el error estándar a través de pliegues de la base de datos, con una o diferentes elegidos utilizando el conjunto de validación de\n",
      "cada pliegue. En TFD, o era validación cruzada en cada diario de probabilidad veces y media en cada pliegue se calcularon.\n",
      "Para MNIST comparamos con otros modelos de la versión (en lugar de binario)-valor real del conjunto de datos.\n",
      "\n",
      "de las gaussianas se obtuvo mediante la validación cruzada en el conjunto de validación. Este procedimiento se introdujo en Breuleux et al. [8] y se utiliza para diversos modelos generativos para la que la probabilidad exacta\n",
      "no es tratable [25, 3, 5]. Los resultados se presentan en la Tabla 1. Este método de estimación de la probabilidad\n",
      "tiene un poco alta varianza y no funciona bien en espacios de alta dimensión, pero es la mejor\n",
      "método disponible para nuestro conocimiento. Los avances en los modelos generativos que se muestra, pero no estimar\n",
      "probabilidad motivar directamente la investigación adicional en la forma de evaluar este tipo de modelos.\n",
      "\n",
      "En las figuras 2 y 3 se muestra muestras extraídas de la red del generador después del entrenamiento. A pesar de que no hacemos\n",
      "afirmación de que estas muestras son mejores que las muestras generadas por los métodos existentes, creemos que estos\n",
      "Las muestras son al menos competitivo con los mejores modelos generativos en la literatura y ponen de manifiesto la\n",
      "potencial del marco de confrontación.\n",
      "\n",
      " \n",
      "\n",
      "Figura 2: Visualización de las muestras procedentes del modelo. espectáculos de columna más a la derecha del ejemplo de formación más cercano de\n",
      "la muestra vecina, con el fin de demostrar que el modelo no ha memorizado el conjunto de entrenamiento. Las muestras\n",
      "están justo al azar dibuja, recogidos a cereza no. A diferencia de la mayoría de las otras visualizaciones de modelos generativos profundas, éstas\n",
      "imágenes muestran muestras reales de las distribuciones de modelo, significa no condicionales que les dieron muestras de unidades ocultas.\n",
      "Por otra parte, estas muestras no están correlacionados porque el proceso de muestreo no depende de la cadena de Markov\n",
      "mezclar. a) MNIST b) TFD c) CIFAR-10 (modelo totalmente conectado) d) CIFAR-10 (discriminador convolucional\n",
      "y el generador “deconvolucional”)SERPS PSPSPS PIEI ELE. PAVAPAPALAVALALALA EZ\n",
      "\n",
      "Figura 3: Dígitos obtenidos por interpolación lineal entre las coordenadas en z espacio del modelo completo.\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "Profundo dirigida profundo no dirigidos generativo;\n",
      "modelos de confrontación\n",
      "modelos gráficos gráfica de modelos autoencoders\n",
      "inerence n eeceH forzadas solución de compromiso.\n",
      "durante el entrenamiento. entre mixin Sincronización de la\n",
      ". Inferencia necesaria MCMC necesitaba e discriminador con\n",
      "El entrenamiento de dur; a 'y poder de\n",
      "urante la formación. aproximado . el generador.\n",
      "ni: la reconstrucción:\n",
      "función de partición’Helvetica.\n",
      "; Generacion\n",
      "degradado.\n",
      "Aprendido variacional MCMC-basa aprendido\n",
      "Inferencia aproximada; ; aproximado\n",
      ". inferencia inferencia\n",
      "inferencia inferencia\n",
      "No hay dificultades de muestreo Requiere Requiere Markov Markov No hay dificultades\n",
      "cadena de la cadena\n",
      "No explícitamente no explícitamente\n",
      "Intratable, puede ser | Intratable, puede ser | representado, pueden estar | representado, puede ser\n",
      "La evaluación de p (x) | aproximada con aproximada con aproximada aproximada con la\n",
      "densidad Parzen densidad AIS AIS Parzen\n",
      "la estimación de la estimación\n",
      "Casi todos los modelos de diseño cuidadoso Cualquier diferenciable Cualquier diferenciables\n",
      "; ; función es función se\n",
      "Modelo extrema diseño incurrir necesaria para asegurar h ‘h llamada‘llamada\n",
      "dificultad múltiples propiedades neue) Miporenealy\n",
      "permitida la permitida\n",
      "\n",
      "Tabla 2: Retos en la modelización generativa: un resumen de las dificultades que encuentran los diferentes enfoques\n",
      "al modelado generativo de profundidad para cada una de las principales operaciones que implican un modelo.\n",
      "\n",
      "6 Ventajas y desventajas\n",
      "\n",
      "Este nuevo marco viene con ventajas y desventajas relativas a marcos de modelos anteriores. Las desventajas son principalmente que no hay una representación explícita de p, (a), y que D\n",
      "debe ser sincronizado bien con G durante el entrenamiento (en particular, G no debe ser entrenado demasiado\n",
      "sin actualizar D, a fin de evitar “el escenario Helvetica” en la que G se derrumba demasiados valores\n",
      "de z en el mismo valor de x para tener suficiente diversidad para modelo pgata), tanto como las cadenas negativas de una\n",
      "máquina de Boltzmann debe mantenerse al día entre las etapas de aprendizaje. Las ventajas son que Markov\n",
      "Nunca se necesitan cadenas, solamente Backprop se utiliza para obtener gradientes, no se necesita ninguna inferencia durante\n",
      "aprendizaje, y una amplia variedad de funciones se pueden incorporar en el modelo. La Tabla 2 resume\n",
      "la comparación de las redes de confrontación con otros generadores de modelado generativo se acerca.\n",
      "\n",
      "Las ventajas antes mencionadas son principalmente computacional. modelos de confrontación también pueden ganar\n",
      "alguna ventaja estadística de la red del generador no está actualizando directamente con ejemplos de datos, pero sólo con gradientes fluyen a través del discriminador. Esto significa que los componentes de la\n",
      "de entrada no se copian directamente en los parámetros del generador. Otra de las ventajas de las redes contradictorio es que pueden representar muy fuerte, incluso distribuciones degeneradas, mientras que los métodos basados ​​en\n",
      "cadenas de Markov requieren que la distribución sea algo borrosa a fin de que las cadenas para poder\n",
      "mezclar entre los modos.\n",
      "\n",
      "7 Conclusiones y trabajo futuro\n",
      "\n",
      "Este marco admite muchas extensiones directas:\n",
      "\n",
      "1. Un condicional modelo generativo p (a | c) se puede obtener mediante la adición de c como entrada a ambos G y D.\n",
      "\n",
      "2. Learned inferencia aproximada se puede realizar mediante la formación de una red auxiliar de predecir z\n",
      "x dados. Esto es similar a la red de inferencia entrenado por el algoritmo de sueño-vigilia [15] pero con\n",
      "la ventaja de que la red de inferencia puede ser entrenado para un generador neto fijo después de que el generador\n",
      "Net ha terminado el entrenamiento.3. Una aproximadamente puede modelar todos los condicionales p (ags | 2 g) en la que S es un subconjunto de los índices\n",
      "de x mediante la formación de una familia de modelos condicionales que los parámetros de las acciones. En esencia, se puede utilizar\n",
      "redes de confrontación para implementar una extensión estocástica del determinista MP-DBM [11].\n",
      "\n",
      "4. El aprendizaje semi-supervisado: características del discriminador o inferencia neta podría mejorar el desempeño de los clasificadores cuando los datos de la etiqueta disponible es limitada.\n",
      "\n",
      "5. Mejora de la eficiencia: la formación se podría acelerar en gran medida por los mejores métodos para divising\n",
      "coordinación de G y D o determinar mejores distribuciones para z muestra de durante el entrenamiento.\n",
      "\n",
      "En este trabajo se ha demostrado la viabilidad de la estructura del modelo de confrontación, lo que sugiere que\n",
      "estas líneas de investigación podrían resultar útiles.\n",
      "\n",
      "Expresiones de gratitud\n",
      "\n",
      "Nos gustaría reconocer Patrice Marcotte, Olivier Delalleau, Kyunghyun Cho, Guillaume\n",
      "Alain y Jason Yosinski útil para los debates. Yann Dauphin comparte su código de evaluación ventana Parzen con nosotros. Nos gustaría dar las gracias a los desarrolladores de Pylearn2 [12] y Teano [7, 1],\n",
      "particularmente Frédéric Bastien quien corrió una característica Teano específicamente para beneficiar a este proyecto. Arnaud Bergeron proporciona un apoyo muy necesario con 4TRX archivos de texto. También nos gustaría dar las gracias\n",
      "Cifar, y Canadá Investigación Sillas de financiación, y calcular Canadá y Québec para Calcul\n",
      "la provisión de recursos computacionales. Ian Goodfellow es apoyada por la beca en 2013 Google\n",
      "Aprendizaje profundo. Por último, nos gustaría dar las gracias a Les Trois Brasseurs para estimular nuestra creatividad.\n",
      "\n",
      "referencias\n",
      "\n",
      "[1] Bastien, F, Lamblin, P., Pascanu, R., Bergstra, J., Goodfellow, I. J., Bergeron, A., Bouchard, N., y\n",
      "Bengio, Y. (2012). Teano: nuevas características y mejoras de velocidad. Aprendizaje y profunda sin supervisión\n",
      "Característica de aprendizaje NIPS 2012 Taller.\n",
      "\n",
      "[2] Bengio, Y. (2009). El aprendizaje profundo arquitecturas para la IA. Ahora editores.\n",
      "\n",
      "[3] Bengio, Y., Mesnil, G., Dauphin, Y., y Rifai, S. (2013a). Mejor mezcla a través de representaciones profundas. En\n",
      "ICML’/ 3.\n",
      "\n",
      "[4] Bengio, Y., Yao, L., Alain, G., y Vincent, P. (2013b). Generalizadas eliminación de ruido auto-generativa como codificadores\n",
      "modelos. En NJPS26. Fundación pellizcos.\n",
      "\n",
      "[5] Bengio, Y., Thibodeau-Laufer, E., y Yosinski, J. (2014A). Profunda generativa estocástico redes entrenable\n",
      "por Backprop. En ICML’/ 4.\n",
      "\n",
      "[6] Bengio, Y., Thibodeau-Laufer, E., Alain, G., y Yosinski, J. (2014b). redes estocásticos generativos profundas entrenable por Backprop. En Actas de la Conferencia Internacional 30ª en aprendizaje automático\n",
      "(ICML’14).\n",
      "\n",
      "[7] Bergstra, J., Breuleux, O., Bastien, F., Lamblin, P., Pascanu, R., Desjardins, G., Turian, J., Warde-Farley,\n",
      "D., y Bengio, Y. (2010). Teano: una CPU y GPU matemáticas expresión compilador. En Actas de la\n",
      "Python para Scientific Computing Conference (SciPy). Presentación oral.\n",
      "\n",
      "[8] Breuleux, O., Bengio, Y., y Vincent, P. (2011). generar rápidamente muestras representativas de una\n",
      "proceso RBM-deriva. Neural Computation, 23 (8), 2053-2073.\n",
      "\n",
      "[9] Glorot, X., Bordes, A., y Bengio, Y. (2011). redes neuronales rectificador de profundidad escasa. En AISTATS'201 1.\n",
      "\n",
      "[10] Goodfellow, I. J., Warde-Farley, D., Mirza, M., Courville, A., y Bengio, Y. (2013a). MAXOUT redes.\n",
      "En ICML'2013.\n",
      "\n",
      "[11] Goodfellow, I. J., Mirza, M., Courville, A., y Bengio, Y. (2013b). Multi-predicción profunda Boltzmann\n",
      "máquinas. En NJPS'2013.\n",
      "\n",
      "[12] Goodfellow, I. J., Warde-Farley, D., Lamblin, P., Dumoulin, V., Mirza, M., Pascanu, R., Bergstra,\n",
      "J., Bastien, F y Bengio, Y. (2013c). Pylearn2: una biblioteca de investigación de aprendizaje automático. arXiv\n",
      "arXiv: 1308.4214.\n",
      "\n",
      "[13] Gutmann, M. y Hyvarinen, A. (2010). estimación del ruido-contrastivo: Un nuevo principio para la estimación\n",
      "modelos estadísticos no normalizadas. En AJSTATS'2010.\n",
      "\n",
      "[14] Hinton, G., Deng, L., Dahl, G. E., Mohamed, A., Jaitly, N., Senior, A., Vanhoucke, V., Nguyen, P.,\n",
      "Sainath, T., y Kingsbury, B. (2012a). redes neuronales profundas para el modelado acústico en el reconocimiento de voz.\n",
      "Revista IEEE Procesamiento de Señales, 29 (6), 82-97.\n",
      "\n",
      "[15] Hinton, G. E., Dayan, P., Frey, B. J., y Neal, R. M. (1995). El algoritmo de sueño-vigilia para no supervisado\n",
      "Redes neuronales. Science, 268, 1558-1161.[16] Hinton, G. E., Osindero, S., y Teh, Y. (2006). Un algoritmo de aprendizaje rápido para redes de creencias profundas. Neural\n",
      "Computation, 18, 1527-1554.\n",
      "\n",
      "[17] Hinton, G. E., Srivastava, N., Krizhevsky, A., Sutskever, I., y Salakhutdinov, R. (2012b). Mejorando\n",
      "redes neuronales mediante la prevención de co-adaptación de detectores de rasgos. Informe técnico, arXiv: 1207.0580.\n",
      "\n",
      "[18] Hyvarinen, A. (2005). Estimación de modelos estadísticos no normalizados utilizando correspondencia de puntuación. J. máquina\n",
      "Learning Res., 6.\n",
      "\n",
      "[19] Jarrett, K., Kavukcuoglu, K., Ranzato, M., y LeCun, Y. (2009). ¿Cuál es la mejor arquitectura de múltiples etapas\n",
      "para el reconocimiento de objetos? En Proc. Iccv (ICCV'09), páginas 2146-2153.\n",
      "IEEE.\n",
      "\n",
      "[20] Kingma, D. P. y Welling, M. (2014). Auto-codificación de Bayes variacional. En Actas de la Conferencia Internacional sobre Representaciones de Aprendizaje (ICLR).\n",
      "\n",
      "[21] Krizhevsky, A. y Hinton, G. (2009). Aprender múltiples capas de características de pequeñas imágenes. Técnico\n",
      "informe de la Universidad de Toronto.\n",
      "\n",
      "[22] Krizhevsky, A., Sutskever, I., y Hinton, G. (2012). Clasificación IMAGEnet con profunda convolucional\n",
      "Redes neuronales. En NJPS'2012.\n",
      "\n",
      "[23] LeCun, Y., Bottou, L., Bengio, Y., y Haffner, P. (1998). aprendizaje basado en gradiente aplicado a documentos\n",
      "reconocimiento. Actas de la IEEE, 86 (11), 2278-2324.\n",
      "\n",
      "[24] Rezende, D. J., Mohamed, S., y Wierstra, D. (2014). backpropagation estocástico y aproximada\n",
      "Inferencia en modelos generativos profundas. Informe técnico, arXiv: 1401.4082.\n",
      "\n",
      "[25] Rifai, S., Bengio, Y., Dauphin, Y., y Vincent, P. (2012). Un proceso generativo para el muestreo de contracción\n",
      "auto-codificadores. En ICML’/ 2.\n",
      "\n",
      "[26] Salakhutdinov, R. y Hinton, G. E. (2009). máquinas profunda Boltzmann. En AISTATS'2009, páginas 448--\n",
      "455.\n",
      "\n",
      "[27] Smolensky, P. (1986). procesamiento de la información en los sistemas dinámicos: Fundamentos de la teoría de la armonía. En\n",
      "D. E. Rumelhart y McClelland J. L., editores, distribuido paralelo Processing, volumen 1, capítulo 6, páginas\n",
      "194-281. MIT Press, Cambridge.\n",
      "\n",
      "[28] Susskind, J., Anderson, A., y Hinton, G. E. (2010). La cara conjunto de datos de Toronto. Informe Técnico UTML\n",
      "TR 2010-001, U. de Toronto.\n",
      "\n",
      "[29] Tieleman, T. (2008). El entrenamiento de máquinas de Boltzmann restringidas utilizando aproximaciones a la probabilidad\n",
      "degradado. En W. W. Cohen, A. McCallum, y S. T. Roweis, editores, ICML 2008, páginas 1064-1071. ACM.\n",
      "\n",
      "[30] Vicente, P., Larochelle, H., Bengio, Y., y Manzagol, P.-A. (2008). La extracción y la composición robusta\n",
      "cuenta con autoencoders eliminación de ruido. En ICML 2008.\n",
      "\n",
      "[31] Younes, L. (1999). En la convergencia de los algoritmos estocásticos de Markov a medida que disminuye rápidamente\n",
      "Ergodicidad tasas. Estocástica y estocástico Reports, 65 (3), 177-228.\n"
     ]
    }
   ],
   "source": [
    "file = open(\"out_translated_text.txt\", \"r\", encoding='utf-8')\n",
    "print(file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
